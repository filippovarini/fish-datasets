{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and visualise the [DeepFish](https://github.com/alzayats/DeepFish) dataset\n",
    "\n",
    "This dataset includes count, classification, and segmentation labels; we are only using the segmentation labels in this notebook, and because we are training a detector, we are reducing them to boxes.  Segmentation labels are stored as images, not as text, so we need to parse the connected components from the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import supervision as sv\n",
    "\n",
    "from skimage import measure\n",
    "from tqdm import tqdm\n",
    "\n",
    "source_url = 'http://data.qld.edu.au/public/Q5842/2020-AlzayatSaleh-00e364223a600e83bd9c3f5bcd91045-DeepFish/DeepFish.tar'\n",
    "\n",
    "dataset_shortname = \"deepfish\"\n",
    "download_base = os.path.join(os.path.expanduser('~/data'),dataset_shortname)\n",
    "segmentation_base = os.path.join(download_base,'DeepFish','Segmentation')\n",
    "segmentation_mask_base = os.path.join(segmentation_base,'masks/valid')\n",
    "segmentation_image_base = os.path.join(segmentation_base,'images/valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_dir,exist_ok=True)\n",
    "local_tar_file = os.path.join(download_base,os.path.split(source_url)[-1])\n",
    "print('Downloading data to {}'.format(local_tar_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O {local_tar_file} {source_url}\n",
    "!tar -xvf {local_tar_file} -C {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate mask files\n",
    "\n",
    "The annotations are stored as image masks, we want to find connected components in those masks and convert to boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(segmentation_mask_base), 'Folder {} does not exist'.format(segmentation_mask_base)\n",
    "valid_masks = [os.path.join(segmentation_mask_base,fn) for fn in \\\n",
    "               os.listdir(segmentation_mask_base)]\n",
    "print('Found {} mask files'.format(len(valid_masks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate all files as a consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install megadetector-utils\n",
    "from megadetector.utils.path_utils import find_images\n",
    "image_files_relative = find_images(download_base,recursive=True,return_relative_paths=True)\n",
    "print('Dataset contains a total of {} images'.format(len(image_files_relative)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to convert segmentation mask images to bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxes_from_mask_image(mask_file):\n",
    "    \"\"\"\n",
    "    Load a binary image, find connected components, and convert to COCO-formatted bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        mask_file (str): Path to the binary image file\n",
    "        \n",
    "    Returns:\n",
    "        dict: COCO format annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the image\n",
    "    mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    image_id = os.path.relpath(mask_file,segmentation_mask_base).replace('\\\\','/')\n",
    "    image_id = os.path.splitext(image_id)[0]\n",
    "    \n",
    "    # Ensure binary image (threshold if not already binary)\n",
    "    _, binary = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find connected components\n",
    "    labels = measure.label(binary, connectivity=2)\n",
    "    regions = measure.regionprops(labels)\n",
    "    \n",
    "    # Prepare COCO-formatted annotations\n",
    "    annotations = []\n",
    "    for idx, region in enumerate(regions):\n",
    "        # Get bounding box (y1, x1, y2, x2)\n",
    "        bbox = region.bbox\n",
    "        \n",
    "        # Convert to COCO format [x, y, width, height]\n",
    "        coco_bbox = [\n",
    "            bbox[1],                    # x\n",
    "            bbox[0],                    # y\n",
    "            bbox[3] - bbox[1],         # width\n",
    "            bbox[2] - bbox[0]          # height\n",
    "        ]\n",
    "        \n",
    "        # Create annotation entry\n",
    "        annotation = {\n",
    "            'id': image_id + '_' + str(idx).zfill(3),\n",
    "            'image_id': image_id,\n",
    "            'category_id': 1,\n",
    "            'bbox': coco_bbox,            \n",
    "        }\n",
    "        annotations.append(annotation)\n",
    "    \n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert mask images to bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_max_file = None\n",
    "\n",
    "annotation_records = []\n",
    "\n",
    "for i_mask,mask_file in tqdm(enumerate(valid_masks),total=len(valid_masks)):\n",
    "\n",
    "    if debug_max_file is not None and i_mask > debug_max_file:\n",
    "        break\n",
    "\n",
    "    coco_formatted_annotations = get_boxes_from_mask_image(mask_file)\n",
    "    annotation_records.extend(coco_formatted_annotations)\n",
    "\n",
    "print('Created {} annotations'.format(len(annotation_records)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a complete COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate images\n",
    "assert os.path.isdir(segmentation_image_base)\n",
    "valid_images = [os.path.join(segmentation_image_base,fn) for fn in \\\n",
    "               os.listdir(segmentation_image_base)]\n",
    "print('Found {} image files'.format(len(valid_images)))\n",
    "\n",
    "assert len(valid_images) == len(valid_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_data = {}\n",
    "coco_data['info'] = {}\n",
    "coco_data['categories'] = [{'name':'fish','id':1}]\n",
    "coco_data['annotations'] = annotation_records\n",
    "coco_data['images'] = []\n",
    "\n",
    "for image_file_abs in tqdm(valid_images):\n",
    "    im = {}\n",
    "    im_cv = cv2.imread(mask_file)\n",
    "    image_id = os.path.splitext(os.path.basename(image_file_abs))[0]\n",
    "    im['id'] = image_id\n",
    "    im['file_name'] = image_file_abs.replace('\\\\','/')\n",
    "    im['height'] = im_cv.shape[0]\n",
    "    im['width'] = im_cv.shape[1]\n",
    "\n",
    "    coco_data['images'].append(im)\n",
    "\n",
    "coco_dataset_file = os.path.join(download_base,'deepfish_coco.json')\n",
    "with open(coco_dataset_file,'w') as f:\n",
    "    json.dump(coco_data,f,indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path=segmentation_image_base,\n",
    "    annotations_path=coco_dataset_file,\n",
    ")\n",
    "\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Dataset classes: {dataset.classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize an image grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "image_example = None\n",
    "\n",
    "# random.seed(0)\n",
    "\n",
    "annotated_images = []\n",
    "for _ in range(16):\n",
    "   \n",
    "    i = random.randint(0, len(dataset))    \n",
    "    _, image, annotations = dataset[i]\n",
    "    labels = [dataset.classes[class_id] for class_id in annotations.class_id]\n",
    "\n",
    "    annotated_image = image.copy()\n",
    "    annotated_image = box_annotator.annotate(annotated_image, annotations)\n",
    "    annotated_image = label_annotator.annotate(annotated_image, annotations, labels)\n",
    "    annotated_images.append(annotated_image)\n",
    "    \n",
    "sv.plot_images_grid(\n",
    "    annotated_images,\n",
    "    grid_size=(4, 4),\n",
    "    titles=None,\n",
    "    size=(20, 12),\n",
    "    cmap=\"gray\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write one visualized image to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_image = 100\n",
    "_, image, annotations = dataset[i_image]\n",
    "labels = [dataset.classes[class_id] for class_id in annotations.class_id]\n",
    "\n",
    "annotated_image = image.copy()\n",
    "annotated_image = box_annotator.annotate(annotated_image, annotations)\n",
    "annotated_image = label_annotator.annotate(annotated_image, annotations, labels)\n",
    "\n",
    "sv.plot_image(annotated_image)\n",
    "\n",
    "sample_image_output_file = os.path.join(download_base,'deepfish_sample.jpg')\n",
    "cv2.imwrite(sample_image_output_file,annotated_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
